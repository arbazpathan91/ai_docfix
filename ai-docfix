#!/usr/bin/env python
import sys
import os
import argparse
from ai_docfix.hook import main

def cli():
    """Command line interface."""
    parser = argparse.ArgumentParser(
        description="AI DocFix - Auto-generate docstrings using LiteLLM"
    )
    
    # Allow overriding the model via CLI flag
    parser.add_argument(
        '--model', 
        type=str, 
        help='Override the AI model (e.g., "vertex_ai/gemini-1.5-flash", "gpt-4o")'
    )
    
    # Accept specific files to process
    parser.add_argument(
        'files', 
        nargs='*', 
        help='Specific files to process (if empty, defaults to git staged files)'
    )
    
    args = parser.parse_args()
    
    # If user provided a model flag, set it in the environment
    # This allows llm.py/config.py to pick it up without changing code
    if args.model:
        os.environ["AI_DOCFIX_MODEL"] = args.model
    
    # Pass the list of files (if any) to the hook logic
    sys.exit(main(files=args.files))

if __name__ == "__main__":
    cli()